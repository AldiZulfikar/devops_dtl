{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "245240de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numbers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from jcopdl.callback import Callback, set_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa509b0",
   "metadata": {},
   "source": [
    "# Dataset & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a80f519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeImage():\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        th, tw = self.size\n",
    "        return img.resize((th, tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82364036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaceCrop(object):\n",
    "    \"\"\"Crops the given PIL.Image at the particular index.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (w, h), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, start_x, start_y):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.start_x = start_x\n",
    "        self.start_y = start_y\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL.Image: Cropped image.\n",
    "        \"\"\"\n",
    "        th, tw = self.size\n",
    "        return img.crop((self.start_x, self.start_y, self.start_x + tw, self.start_y + th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6c848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_size = 256\n",
    "batch_size = 64\n",
    "crop_size = 224\n",
    "\n",
    "start_center = (resize_size - crop_size - 1) / 2\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    ResizeImage(resize_size),\n",
    "    PlaceCrop(crop_size, start_center, start_center),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"data/ant-1.6-preprop/\", transform = train_transform)\n",
    "trainloader = DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers=4)\n",
    "\n",
    "test_set = datasets.ImageFolder(\"data/poi-3.0-preprop/\", transform = test_transform)\n",
    "testloader = DataLoader(test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b02cfb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buggy', 'clean']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data = train_set.classes\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ccb44",
   "metadata": {},
   "source": [
    "# Arsitektur & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed13071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8449ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResNet(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(pretrained = True)\n",
    "        self.freeze()\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ba4be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    \"output_size\": len(label_data),\n",
    "    \"batch_size\": batch_size,\n",
    "    \"crop_size\": crop_size\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae931d",
   "metadata": {},
   "source": [
    "# Phase 1 : Adaptation (Ir standard + patience kecil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5acb16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelResNet(config.output_size).to(device)\n",
    "oriterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "callback = Callback(model, config, early_stop_patience=2, outdir=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0548730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def loop_fn (mode, dataset, dataloader, model, criterion, optimizer, device):\n",
    "    if mode == \"train\":\n",
    "        model.train()\n",
    "    elif mode == \"test\":\n",
    "        model.eval()\n",
    "    cost = correct = 0\n",
    "    for feature, target in tqdm(dataloader, desc=mode.title()):\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        output = model (feature) \n",
    "        loss = criterion (output, target)\n",
    "        if mode == \"train\":\n",
    "            loss. backward() \n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "        cost + loss.item() * feature. shape [0]\n",
    "        correct += (output.argmax (1) == target).sum().item()\n",
    "    cost = cost/len(dataset) \n",
    "    acc = correct/len(dataset) \n",
    "    return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47877753",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ef1cc69b6667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtest_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device) \n",
    "    with torch.no_grad():\n",
    "        test_cost, test_score = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n",
    "    # Logging \n",
    "    callback.log(train_cost, test_cost, train_score, test_score)\n",
    "    # Checkpoint \n",
    "    callback.save_checkpoint()\n",
    "    # Runtime Plotting \n",
    "    callback.cost_runtime_plotting() \n",
    "    callback.score_runtime_plotting()\n",
    "    # Early Stopping \n",
    "    if callback.early_stopping (model, monitor=\"test_score\"):\n",
    "        callback.plot_cost() \n",
    "        callback.plot_score() \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963fd4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
