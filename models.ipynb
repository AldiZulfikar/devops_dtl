{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245240de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numbers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from jcopdl.callback import Callback, set_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa509b0",
   "metadata": {},
   "source": [
    "# Dataset & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80f519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeImage():\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        th, tw = self.size\n",
    "        return img.resize((th, tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82364036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaceCrop(object):\n",
    "    \"\"\"Crops the given PIL.Image at the particular index.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (w, h), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, start_x, start_y):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.start_x = start_x\n",
    "        self.start_y = start_y\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL.Image: Cropped image.\n",
    "        \"\"\"\n",
    "        th, tw = self.size\n",
    "        return img.crop((self.start_x, self.start_y, self.start_x + tw, self.start_y + th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "crop_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.7, 1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"data/ant-1.6-preprop/\", transform = train_transform)\n",
    "trainloader = DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers=4)\n",
    "\n",
    "test_set = datasets.ImageFolder(\"data/poi-3.0-preprop/\", transform = test_transform)\n",
    "testloader = DataLoader(test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02cfb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buggy', 'clean']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data = train_set.classes\n",
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ccb44",
   "metadata": {},
   "source": [
    "# Arsitektur & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed13071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8449ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResNet(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.freeze()\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 2),\n",
    "            nn.LogSoftmax(1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba4be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    \"output_size\": len(label_data),\n",
    "    \"batch_size\": batch_size,\n",
    "    \"crop_size\": crop_size\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae931d",
   "metadata": {},
   "source": [
    "# Phase 1 : Adaptation (Ir standard + patience kecil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acb16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelResNet(config.output_size).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "callback = Callback(model, config, early_stop_patience=2, outdir=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0548730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n",
    "    if mode == \"train\":\n",
    "        model.train()\n",
    "    elif mode == \"test\":\n",
    "        model.eval()\n",
    "    cost = correct = 0\n",
    "    for feature, target in tqdm(dataloader, desc=mode.title()):\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        output = model (feature) \n",
    "        loss = criterion (output, target)\n",
    "        if mode == \"train\":\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "        cost + loss.item() * feature.shape [0]\n",
    "        correct += (output.argmax(1) == target).sum().item()\n",
    "    cost = cost/len(dataset) \n",
    "    acc = correct/len(dataset) \n",
    "    return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed2b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2b7528557d45a493538928bac3daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1960468ca2461e9d5de7a1579763a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     1\n",
      "Train_cost  = 0.0000 | Test_cost  = 0.0000 | Train_score = 0.7249 | Test_score = 0.3626 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2db1fd5d0ed45c1aeeb52370a6d139e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/6 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27b78bda27c4d1d9fa6490dd34315a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     2\n",
      "Train_cost  = 0.0000 | Test_cost  = 0.0000 | Train_score = 0.7450 | Test_score = 0.3626 |\n",
      "\u001b[31m==> EarlyStop patience =  1 | Best test_score: 0.3626\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc5d9d9ca5b4a3f9328c61bcbe9c555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd23f895ef54477a2e31c47b156ceff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     3\n",
      "Train_cost  = 0.0000 | Test_cost  = 0.0000 | Train_score = 0.7966 | Test_score = 0.4596 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9aee767864b41de8d0312410c623026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc63b3f1467416692a5e03e7898a77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     4\n",
      "Train_cost  = 0.0000 | Test_cost  = 0.0000 | Train_score = 0.8195 | Test_score = 0.4665 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2d5bc130474368944b0dad30cd9343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/6 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b687aefbc30043608564a89ee5bcdd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True:\n",
    "    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device) \n",
    "    with torch.no_grad():\n",
    "        test_cost, test_score = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n",
    "        \n",
    "    # Logging \n",
    "    callback.log(train_cost, test_cost, train_score, test_score)\n",
    "    \n",
    "    # Checkpoint \n",
    "    callback.save_checkpoint()\n",
    "    \n",
    "    # Runtime Plotting \n",
    "    callback.cost_runtime_plotting() \n",
    "    callback.score_runtime_plotting()\n",
    "    \n",
    "    # Early Stopping \n",
    "    if callback.early_stopping (model, monitor=\"test_score\"):\n",
    "        callback.plot_cost() \n",
    "        callback.plot_score() \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c14eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
